import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import feedparser
import re
from datetime import datetime, timedelta
import theme  # Importe votre fichier de th√®me

# Applique les configurations de page et le th√®me
theme.set_page_defaults()  # Optionnel si main.py g√®re d√©j√† la config globale, mais bonne pratique
theme.apply_theme()

# --- D√©finition des cat√©gories et mots-cl√©s ---
# Dictionnaire des cat√©gories de menaces et des mots-cl√©s associ√©s (en minuscules pour une correspondance insensible √† la casse)
THREAT_CATEGORIES = {
    "Ransomware": ["ransomware", "ran√ßongiciel", "cryptolocker", "wannacry", "notpetya"],
    "Phishing": ["phishing", "hame√ßonnage", "spear phishing", "fraude", "email fraud"],
    "APT (Advanced Persistent Threat)": ["apt", "advanced persistent threat", "groupe de menaces", "state-sponsored"],
    "Vuln√©rabilit√©": ["vulnerability", "vuln√©rabilit√©", "exploit", "cve", "patch", "zero-day"],
    "Malware": ["malware", "logiciel malveillant", "virus", "trojan", "ver", "spyware", "rootkit", "adware"],
    "Fuite de Donn√©es": ["data breach", "fuite de donn√©es", "violation de donn√©es", "compromission", "data leak"],
    "DDoS": ["ddos", "denial of service", "attaque par d√©ni de service"],
    "Cryptojacking": ["cryptojacking", "minage de crypto"],
    "Attaque Cha√Æne d'Approvisionnement": ["supply chain attack", "attaque cha√Æne d'approvisionnement"],
    "S√©curit√© IoT": ["iot security", "s√©curit√© iot", "internet des objets"],
    "S√©curit√© Cloud": ["cloud security", "s√©curit√© cloud", "cloud computing"],
    "Ing√©nierie Sociale": ["social engineering", "ing√©nierie sociale", "arnaque", "scam"],
    "Authentification": ["authentication", "authentification", "mfa", "2fa", "credential stuffing"],
    "Zero Trust": ["zero trust", "zero-trust"],
    "Conformit√©/R√©gulation": ["gdpr", "rgpd", "compliance", "conformit√©", "regulation"],
    "Menace Interne": ["insider threat", "menace interne"],
    "S√©curit√© Mobile": ["mobile security", "s√©curit√© mobile", "android security", "ios security"],
}

# --- Fonctions de collecte de donn√©es ---

def categorize_article(title, summary):
    """
    Cat√©gorise un article bas√© sur les mots-cl√©s pr√©sents dans son titre et son r√©sum√©.
    Retourne une liste de cat√©gories correspondantes ou ['Non cat√©goris√©'] si aucune correspondance.
    """
    found_categories = []
    text_to_analyze = (title + " " + summary).lower()

    for category, keywords in THREAT_CATEGORIES.items():
        for keyword in keywords:
            if re.search(r'\b' + re.escape(keyword) + r'\b', text_to_analyze): # Utilise re.search pour des correspondances de mots entiers
                found_categories.append(category)
                break # Passe √† la cat√©gorie suivante une fois qu'un mot-cl√© est trouv√© pour cette cat√©gorie
    
    if not found_categories:
        return ["Non cat√©goris√©"]
    return sorted(list(set(found_categories))) # Retourne des cat√©gories uniques et tri√©es

def get_rss_feed_data(url):
    """
    R√©cup√®re les articles d'un flux RSS et les enrichit avec une cat√©gorie.
    """
    try:
        feed = feedparser.parse(url)
        articles = []
        for entry in feed.entries:
            title = entry.title if hasattr(entry, "title") else "No title"
            link = entry.link if hasattr(entry, "link") else "No link"
            summary = entry.summary if hasattr(entry, "summary") else "No summary"
            published = (
                entry.published_parsed if hasattr(entry, "published_parsed") else None
            )
            published_date = (
                datetime(*published[:6]).strftime("%Y-%m-%d %H:%M:%S")
                if published
                else "N/A"
            )
            
            # Cat√©gorisation de l'article
            categories = categorize_article(title, summary)

            articles.append(
                {
                    "Source": url,
                    "Titre": title,
                    "Lien": link,
                    "R√©sum√©": summary,
                    "Date": published_date,
                    "Cat√©gories": categories,  # Nouvelle colonne pour les cat√©gories
                }
            )
        return articles
    except Exception as e:
        st.warning(f"Impossible de r√©cup√©rer le flux RSS de {url}: {e}")
        return []

# --- Configuration des sources ---
SOURCES_CTI = {
    "Flux RSS": [
        "https://www.cert.ssi.gouv.fr/alerte/feed/",
        "https://www.cert.ssi.gouv.fr/cti/feed/",
        "https://www.cert.ssi.gouv.fr/actualite/feed/",
        "https://threatpost.com/feed/",
        "https://feeds.feedburner.com/TheHackersNews",
        "https://www.bleepingcomputer.com/feed/",
        "https://www.misp-project.org/feed",
    ],
}

# --- Interface Streamlit ---

st.title("üõ°Ô∏è Veille Cyber Threat Intelligence (CTI)")
st.markdown(
    "Bienvenue dans votre tableau de bord de veille sur les cybermenaces. Explorez les derni√®res actualit√©s et analyses."
)

# Sidebar pour les filtres
st.sidebar.header("Options de la veille")
date_filter = st.sidebar.date_input(
    "Filtrer par date (depuis)", datetime.now() - timedelta(days=7)
)
search_query = st.sidebar.text_input("Rechercher par mot-cl√©")

# R√©cup√©rer toutes les cat√©gories uniques pour le multiselect
all_available_categories = sorted(list(THREAT_CATEGORIES.keys()) + ["Non cat√©goris√©"])
selected_categories = st.sidebar.multiselect(
    "Filtrer par Type de Menace / Cat√©gorie",
    options=all_available_categories,
)

# Bouton pour lancer la veille
if st.sidebar.button("Lancer la veille / Actualiser"):
    all_articles = []

    st.info("Collecte des donn√©es via les flux RSS...")
    for rss_url in SOURCES_CTI["Flux RSS"]:
        articles = get_rss_feed_data(rss_url)
        all_articles.extend(articles)

    if all_articles:
        df = pd.DataFrame(all_articles)
        df["Date"] = pd.to_datetime(
            df["Date"]
        )  # Convertir en datetime pour le filtrage
        st.session_state["data"] = df
        st.success(f"{len(df)} articles collect√©s.")
    else:
        st.warning("Aucun article n'a pu √™tre collect√©. V√©rifiez vos sources.")
else:
    if "data" not in st.session_state:
        st.info(
            "Cliquez sur 'Lancer la veille / Actualiser' pour commencer la collecte."
        )

# Affichage des r√©sultats
if "data" in st.session_state:
    df_filtered = st.session_state["data"].copy()

    # Appliquer le filtre de date
    df_filtered = df_filtered[df_filtered["Date"] >= pd.to_datetime(date_filter)]

    # Appliquer le filtre par mot-cl√©
    if search_query:
        df_filtered = df_filtered[
            df_filtered.apply(
                lambda row: search_query.lower()
                in row.astype(str).str.lower().to_string(),
                axis=1,
            )
        ]

    # Appliquer le filtre par cat√©gorie
    if selected_categories:
        # Un article peut avoir plusieurs cat√©gories, donc nous v√©rifions si au moins une des cat√©gories s√©lectionn√©es est pr√©sente
        df_filtered = df_filtered[
            df_filtered["Cat√©gories"].apply(
                lambda article_categories: any(cat in selected_categories for cat in article_categories)
            )
        ]

    st.subheader(f"Articles collect√©s ({len(df_filtered)} r√©sultats)")

    if not df_filtered.empty:
        # Afficher les articles dans des expanders ou une table
        for index, row in df_filtered.sort_values(
            by="Date", ascending=False
        ).iterrows():
            with st.expander(
                f"**{row['Titre']}** (Source: {row['Source'].split('//')[1].split('/')[0]} - {row['Date'].strftime('%Y-%m-%d %H:%M')})"
            ):
                st.write(f"**R√©sum√©:** {row['R√©sum√©']}")
                st.markdown(f"**Lien:** [Lire l'article]({row['Lien']})")
    else:
        st.info("Aucun article ne correspond √† vos crit√®res de recherche.")

st.sidebar.markdown("---")
st.sidebar.markdown("D√©velopp√© avec ‚ù§Ô∏è et Streamlit")
